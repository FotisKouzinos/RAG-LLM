# RAG-LLM

This repository explores Retrieval-Augmented Generation (RAG) techniques to enhance Large Language Models (LLMs) by integrating them with external knowledge sources. RAG aims to improve the relevance and accuracy of LLM outputs by retrieving pertinent information from authoritative databases during the generation process.

## Overview

Large Language Models are powerful tools capable of performing various natural language processing tasks. However, they can sometimes produce outdated or hallucinated information due to the static nature of their training data. RAG addresses these challenges by combining LLMs with real-time data retrieval mechanisms, ensuring responses are both current and contextually relevant.

## Key Features

- **Dynamic Information Retrieval**: Incorporates external data sources to provide up-to-date information without the need for retraining the model.
- **Enhanced Accuracy**: Reduces the likelihood of generating incorrect or hallucinated content by grounding responses in verified data.
- **Domain Adaptability**: Easily adapts to specific domains or industries by integrating relevant databases and knowledge bases.

## Installation

To utilize the RAG-LLM framework, clone this repository, enter the set_up folder, add a . infront of the env file and run the bellow command:

```bash
docker compose up
